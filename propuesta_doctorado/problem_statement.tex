
\section{Planteamiento del problema y pregunta de investigación}

Los trastornos mentales afectan la cognición, el comportamiento y las emociones de millones de personas en el mundo. Se estima que alrededor de 350 millones de individuos padecen algún trastorno mental \cite{Dehghan-Bonari2023}. Dentro de estos trastornos, el Trastorno por Déficit de Atención e Hiperactividad (TDAH) representa un desafío significativo, afectando aproximadamente al 5\% de la población infantil y adolescente, y al 2.5\% de los adultos, convirtiéndolo en uno de los desordenes neuronales más frecuentes en la infancia y adolescencia, además es una de las principales causas de tratamiento psicológico y psiquiátrico \cite{Salari2023}. Este trastorno no solo dificulta el rendimiento académico y laboral \cite{Ayano2020}, sino que también aumenta el riesgo de presentar otros problemas psiquiátricos, conductas delictivas y adicciones \cite{Faraone2015}.

La detección e intervención temprana del TDAH es esencial para brindar un tratamiento oportuno y efectivo \cite{Kivumbi2019}. Sin embargo, las técnicas diagnósticas actuales presentan limitaciones importantes: muchas pruebas requieren un seguimiento prolongado \cite{Zhou2015-bg}, pueden estar sujetas a interpretaciones subjetivas \cite{LOHANI2023111689} y muchos criterios resultan ineficientes para el diagnostico en adultos \cite{Sibley21042021}. Además, el acceso a un tratamiento clínico y seguimiento es frecuentemente restringido debido a la falta de recursos o la escasez de especialistas \cite{Asherson2022,Pallanti2020}.

El avance en el desarrollo de modelos de aprendizaje automático ha permitido la creación de herramientas que apoyan el diagnóstico de diversas enfermedades, incluido el TDAH \cite{article}. Generalmente, estos modelos utilizan señales electroencefalográficas (EEG) para clasificar registros como pertenecientes a individuos con o sin la enfermedad, mediante un enfoque de clasificación binaria. No obstante, la naturaleza no estacionaria y la complejidad inherente a las señales EEG complican su análisis utilizando modelos tradicionales (insertar cita).

El uso de técnicas de aprendizaje profundo se presenta como una alternativa prometedora, ya que permite extraer características abstractas de las señales EEG mediante una gran cantidad de parámetros (insertar ejemplos y cita). Sin embargo, el entrenamiento de estos modelos requiere grandes volúmenes de datos etiquetados en un marco supervisado, lo que en muchos casos resulta costoso o incluso inviable.

Para superar esta limitación, han surgido los modelos fundacionales, que permiten preentrenar con conjuntos de datos no etiquetados y, posteriormente, ajustar el modelo para tareas específicas utilizando una cantidad significativamente menor de datos etiquetados (insertar cita). Este enfoque aprovecha la estructura subyacente presente en datos sin clasificar, permitiendo que el modelo aprenda representaciones generales robustas. Gracias a este preentrenamiento, el modelo puede transferir conocimientos a tareas concretas, lo que reduce la dependencia de grandes volúmenes de datos anotados y agiliza el proceso de adaptación a nuevos escenarios. Además, esta metodología facilita la integración de información heterogénea, permitiendo que el sistema se ajuste a variaciones en los protocolos de adquisición, como diferencias en la tasa de muestreo o en el número de canales (insertar cita).

En el ámbito clínico es crucial no solo obtener una predicción diagnóstica, sino también disponer de una medida de la incertidumbre asociada a dicha predicción. En este sentido, los procesos gaussianos ofrecen una solución al generar distribuciones de probabilidad en lugar de valores deterministas, lo que facilita el modelado de funciones complejas y la realización de tareas de clasificación (insertar estudios y cita). Sin embargo, la integración de procesos gaussianos con modelos fundacionales aún es un área poco explorada y con un gran potencial de mejora.

Otro aspecto relevante es la variabilidad presente en los conjuntos de datos no etiquetados utilizados durante el preentrenamiento. Estas bases de datos pueden presentar diferencias en los estándares de adquisición, tales como valores ausentes, variaciones en la tasa de muestreo o en el número de canales. Descartar estos datos implicaría perder información valiosa, por lo que es fundamental desarrollar un modelo fundacional capaz de gestionar eficazmente estas inconsistencias y aprovechar al máximo la información disponible.

\textbf{Pregunta de investigación:}  
¿De qué manera la integración de modelos fundacionales basados en aprendizaje profundo y procesos gaussianos puede mejorar la detección temprana del TDAH mediante el análisis de señales EEG, considerando la variabilidad y la presencia de datos incompletos en los protocolos de adquisición? (insertar cita)
