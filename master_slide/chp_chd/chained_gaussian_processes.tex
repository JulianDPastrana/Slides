\section[Chained Correlated Gaussian Processes]{Chained Correlated Gaussian Processes: Transforming Gaussian Processes into Likelihood Parameters}

\subsection{Mathematical Framework}

\begin{frame}{Likelihood Model}
	\justifying
	We assume the outputs are conditionally independent given a parameter vector $\boldsymbol{\theta}_d \in \mathbb{R}^{J_d}$, where:
	
	\begin{itemize}
		\item $J_d$ is the number of parameters that define the likelihood for the $d$-th output.
		\item $\boldsymbol{\theta}_d = [\theta_{d,1}, \theta_{d,2}, \dots, \theta_{d,J_d}]^\top$.
	\end{itemize}
	
	The complete parameter vector across all outputs is denoted as:
	\begin{equation*}
		\boldsymbol{\theta} = [\boldsymbol{\theta}_1^\top, \boldsymbol{\theta}_2^\top, \dots, \boldsymbol{\theta}_D^\top]^\top \in \mathbb{R}^{J}
	\end{equation*}
	where $J = \sum_{d=1}^D J_d$.
	
	The likelihood of observing all output realizations, $\mathbf{y}$, given the parameter vector $\boldsymbol{\theta}$, is expressed as the product of individual likelihoods:
	\begin{equation*}
		p(\mathbf{y} \mid \boldsymbol{\theta}) = \prod_{d=1}^D p\left(\mathbf{y}_d \mid \boldsymbol{\theta}_d\right)
	\end{equation*}
\end{frame}


\begin{frame}{Chained Gaussian Process}
	Each $j$-th parameter of the $d$-th likelihood distribution $\theta_{d,j}$ is a deterministic transformation of a latent Gaussian Process prior realization $f_{dj}$, given by $\theta_{d,j} = g_{d,j}(f_{d,j})$.
	\begin{itemize}
		\item $\mathbf{f}_{d,j} = [f_{d,j,1}, f_{d,j,2}, \cdots, f_{d,j,N}]^\top \in \mathbb{R}^{N}$ , where $f_{d,j,n} = f_{d,j}(\mathbf{x}_n)$.
		\item $\mathbf{f}_{d} = [\mathbf{f}_{d,1}^\top, \mathbf{f}_{d,2}^\top, \cdots, \mathbf{f}_{d,J_d}^\top]^\top \in \mathbb{R}^{J_dN}$ 
		\item $\mathbf{f} = [\mathbf{f}_1^\top, \mathbf{f}_2^\top, \cdots, \mathbf{f}_D^\top]^\top \in \mathbb{R}^{JN}$ 
	\end{itemize}
	
	The conditionally independent likelihood is then formulated as follows: \begin{equation*}
		p(\mathbf{y} \mid \boldsymbol{\theta}) = p(\mathbf{y} \mid \mathbf{f}) = \prod_{d=1}^D p(\mathbf{y}_d\mid \mathbf{f}_{d}) = \prod_{d=1}^D \prod_{n=1}^N p(y_{d,n}\mid f_{d,1,n}, \cdots, f_{d, J_d, n})
	\end{equation*}
	This formulation introduces $J$ latent parameter functions $f_{d,j}(\mathbf{x})$, each governed by a GP prior.
	
\end{frame}

\begin{frame}{LMCGP for Chained GPs}
	The correlation between \(f_{d,j}(\mathbf{x})\) and \(f_{d',j'}(\mathbf{x}')\) can be modeled by using the LMCGP framework:
	\begin{equation*}
		\begin{aligned}
			f_{d,j}(\mathbf{x}) &= \sum_{q=1}^Q a_{d,j,q} u_{q}(\mathbf{x}) \quad &
			u_{q}(\mathbf{x}) &\sim \mathcal{GP}(0, k_{q}(\mathbf{x}, \mathbf{x}')) 
		\end{aligned}\label{eq:chd_cov}
	\end{equation*}
	Where $k_q$ is the kernel function of the independent process $q$ government by the parameters set $\Phi_q$. The cross-covariance function of the latent parameter GP $\mathbf{f}$ is as follows:
	\begin{equation*}
			k_{(d,j), (d',j')}(\mathbf{x}, \mathbf{x}') =\sum_{q=1}^Q b^q_{(d,j), (d',j')} k_{q}(\mathbf{x}, \mathbf{x}')
	\end{equation*}
	where $b^q_{(d,j), (d',j')} = a_{d,j,q}a_{d',j',q}$ encodes the interactions among the outputs models, meanwhile, $k_{q}(\mathbf{x}, \mathbf{x}')$ mange the interaction among input space.
\end{frame}

\begin{frame}{Variational Inference and ELBO}
	We can extent our variational inference to include conditional independent likelihood function, providing the following ELBO:
	
\begin{equation*}
	\begin{split}
	\mathcal{L} &= \sum_{d=1}^D \sum_{n=1}^{N} \mathbb{E}_{q(f_{d,1,n}), \cdots, q(f_{d,J_d,n})} 
	\left\{ \log p\left( y_{d,n} \mid f_{d,1,n}, \cdots, f_{d,J_d,n} \right) \right\} \\
	&- \sum_{q=1}^Q \text{KL}\left\{ q(\mathbf{u}_q) \parallel p(\mathbf{u}_q) \right\}
	\end{split}
\end{equation*}

The expectation values can be approximated via Monte Carlo methods.
	
\end{frame}

\begin{frame}{Latent posterior and Predictive distribution}
	Consider a test points set $X_{*} \in \mathcal{X}$. Assuming a good approximation of the variational posterior $p(\mathbf{u} \mid \mathbf{y}) \approx q(\mathbf{u})$, the posterior of latent parameter function vector at test points $\mathbf{f}_*$ is
	\begin{equation*}
		q(\mathbf{f}_*) = \int p(\mathbf{f}_* \mid \mathbf{u}) q(\mathbf{u}) d\mathbf{u}
	\end{equation*}
	The predictive distribution for a new observation $\mathbf{y}_*$, given the observed data $\mathbf{y}$, can thus be approximated as:
	\begin{equation*}
		p(\mathbf{y}_* \mid \mathbf{y}) \approx \int p(\mathbf{y}_* \mid \mathbf{f}_*) q(\mathbf{f}_*) \, d\mathbf{f}_*,
	\end{equation*}
	
	which integrates over the latent function vector $\mathbf{f}_*$ to account for its uncertainty in the prediction of $\mathbf{y}_*$.

\end{frame}

\begin{frame}{Model Setup}
	We again make use of squared exponential kernel to construct the covariance function and Adam + NG framework to train the models.
	
	\begin{itemize} 
	
	\item \textbf{Gaussian Likelihood}
	
	\begin{equation*}
		p(\mathbf{y} \mid \mathbf{f}) = \prod_{d=1}^{D} \prod_{n=1}^{N} \mathcal{N}\left(y_{d,n} \mid g_{d,1}(f_{d,1,n}), g_{d,2}(f_{d,2,n}) \right)
	\end{equation*}
	In this formulation, \(g_{d,1}(\cdot) = \cdot\), while \(g_{d,2}(\cdot) = \ln(\exp(\cdot) + 1)\). We call this model Chd Normal.
	
	\item \textbf{Gamma Likelihood}
	
	\begin{equation*}
		p(\mathbf{y} \mid \mathbf{f}) = \prod_{d=1}^{D} \prod_{n=1}^{N} \mathcal{G}amma\left( y_{d,n} \mid g_{d,1}(f_{d,1,n}), g_{d,2}(f_{d,2,n}) \right)
	\end{equation*}
	
	In this formulation \(g_{d,1}(\cdot) = g_{d,2}(\cdot) = \ln(\exp(\cdot) + 1)\). We call this model Chd Gamma.
	\end{itemize}
	
		
\end{frame}

\subsection{Results and Discussions}

\begin{frame}{Tuning Q for Chd Normal}
	\begin{figure}[htbp]
		\centering
		\setlength\figurewidth{0.5\columnwidth} 
		\setlength\figureheight{0.3\columnwidth}
		\subfloat[CRPS]{\input{chp_chd/figures/CRPS_chd_normal}}
		\subfloat[MSE]{\input{chp_chd/figures/MSE_chd_normal}}\\
		\vspace{-0.2cm}
		\subfloat[MSLL]{\input{chp_chd/figures/MSLL_chd_normal}}
		\subfloat[NLPD]{\input{chp_chd/figures/NLPD_chd_normal}}\\
		\vspace{-0.5cm}
		\caption{Performance metrics for ChdGP Normal model as a function of the number of independent GPs Q.}
	\end{figure}
\end{frame}

\subsection{Performance Analysis}
\begin{frame}{ChdGP Normal vs LMCGP}
	\begin{figure}[htbp]
		\centering
		\setlength\figurewidth{0.53\columnwidth}
		\setlength\figureheight{0.5\columnwidth}
		
		\subfloat[NLPD]{\input{chp_chd/figures/NLPD_peformance_chdnormal}}
		\hfill
		\subfloat[MSLL]{\input{chp_chd/figures/MSLL_peformance_chdnormal}}
		
		\caption{Bar plots comparing the performance of LMCGP, and ChdGP Normal models for different \(H\) values.}
	\end{figure}
\end{frame}

\begin{frame}{ChdGP Normal Forecasting}
	\justifying
	\begin{figure}[htbp]
		\setlength\figurewidth{0.52\columnwidth} 
		\setlength\figureheight{0.29\columnwidth}
		
		\subfloat[$T.$]{\input{chp_chd/figures/chd_normal_forecasting_SALVAJINA}}\hfill
		\subfloat[$A.$]{\input{chp_chd/figures/chd_normal_forecasting_AMANI}}\\[-0.5cm]
		\subfloat[$I.$]{\input{chp_chd/figures/chd_normal_forecasting_SAN LORENZO}}\hfill
		\subfloat[$O.$]{\input{chp_chd/figures/chd_normal_forecasting_ESMERALDA}}\\[-0.4cm]
		
		\caption{Test data for four reservoirs in one day ahead ChdGP Normal model prediction ($H=1$). Blue shaded areas represent the $95\%$ centered confidence interval for the model's prediction.}
	\end{figure}
\end{frame}

\begin{frame}{Tuning Q for Chd Gamma}
	\begin{figure}[htbp]
		\centering
		\setlength\figurewidth{\columnwidth} 
		\setlength\figureheight{0.55\columnwidth}
		\input{chp_chd/figures/NLPD_chd_gamma}
		\caption{NLPD metric for ChdGP Gamma models as a function of the number of independent GPs.}
	\end{figure}
\end{frame}

\subsection{Performance Analysis}

\begin{frame}{ChdnGP Gamma vs ChdGP Normal}
	\begin{figure}[htbp]
		\centering
		\setlength\figurewidth{\columnwidth} 
		\setlength\figureheight{0.55\columnwidth}
		\input{chp_chd/figures/NLPD_peformance_chdgamma}
		\caption{Comparison of NLPD metric across different prediction horizons for the ChdGP Normal, and ChdGP Gamma models.}
	\end{figure}
	
\end{frame}

\begin{frame}{ChdGP Gamma Forecasting}
	\centering
	\begin{figure}[htbp]
		\tiny
		\setlength\figurewidth{0.52\columnwidth} 
		\setlength\figureheight{0.30\columnwidth}
		
		\subfloat[$T.$]{\input{chp_chd/figures/chd_gamma_forecasting_SALVAJINA}}\hfill
		\subfloat[$A.$]{\input{chp_chd/figures/chd_gamma_forecasting_AMANI}}\\[-0.5cm]
		\subfloat[$I.$]{\input{chp_chd/figures/chd_gamma_forecasting_SAN LORENZO}}\hfill
		\subfloat[$O.$]{\input{chp_chd/figures/chd_gamma_forecasting_ESMERALDA}}\\[-0.4cm]
		
		\caption{Test data for four reservoirs in one day ahead ChdGP Normal model prediction. Blue shaded areas represent the $95\%$ centered confidence interval for the model's prediction.}
	\end{figure}
\end{frame}

\begin{frame}{To Conclude}
	
	\begin{itemize}
		\justifying
		\item The ChdGP model generalizes all previously developed GP-based models, enhancing expressiveness by modeling likelihood parameters and enabling the handling of natural output restrictions.
		
		\item The ChdGP Normal model outperformed the LMCGP model across all forecasting horizons, primarily due to its ability to adaptively vary data noise over the input space, providing a more refined capture of the underlying data structure.
		
		\item The ChdGP with Gamma likelihood ensured non-negative predictions. The tuning process revealed a significant improvement in model stability as the number of independent GPs ($Q$) increased, suggesting superior data modeling capabilities.
		
		\item The Gamma likelihood configuration outperformed the Gaussian likelihood across all evaluated horizons by avoiding the allocation of predictive distribution mass to negative values and utilizing an asymmetric distribution to more effectively handle peak outliers.
		
	\end{itemize}
\end{frame}

