
@inproceedings{toadstool,
	title = {Toadstool: A Dataset for Training Emotional Intelligent Machines Playing Super Mario Bros},
	author = {
	Svoren, Henrik and Thambawita, Vajira and Halvorsen, P\r{a}l and
	Jakobsen, Petter and Garcia-Ceja, Enrique and Noori, Farzan Majeed and
	Hammer, Hugo L. and Lux, Mathias and Riegler, Michael Alexander and
	Hicks, Steven Alexander
	},
	year = {2020},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/3339825.3394939},
	booktitle = {Proceedings of the 11th ACM Multimedia Systems Conference},
	pages = {309â€“314},
	numpages = {6},
	location = {Istanbul, Turkey},
	series = {MMSys '20}
}

@inproceedings{garbarino2014empatica,
	author    = {Garbarino, M. and Lai, M. and Bender, D. and Picard, R. W. and Tognetti, S.},
	title     = {Empatica E3 -- A wearable wireless multi-sensor device for real-time computerized biofeedback and data acquisition},
	booktitle = {Proceedings of the International Conference on Wireless Mobile Communication and Healthcare (ICWMCHM)},
	year      = {2014},
	pages     = {39--42}
}

@article{giraldo2021fully,
	title={A fully natural gradient scheme for improving inference of the heterogeneous multioutput Gaussian process model},
	author={Giraldo, Juan-Jos{\'e} and Alvarez, Mauricio A},
	journal={IEEE Transactions on Neural Networks and Learning Systems},
	volume={33},
	number={11},
	pages={6429--6442},
	year={2021},
	publisher={IEEE}
}

@InProceedings{pmlr-v84-salimbeni18a,
	title = 	 {Natural Gradients in Practice: Non-Conjugate Variational Inference in Gaussian Process Models},
	author = 	 {Salimbeni, Hugh and Eleftheriadis, Stefanos and Hensman, James},
	booktitle = 	 {Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics},
	pages = 	 {689--697},
	year = 	 {2018},
	editor = 	 {Storkey, Amos and Perez-Cruz, Fernando},
	volume = 	 {84},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {09--11 Apr},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v84/salimbeni18a/salimbeni18a.pdf},
	url = 	 {https://proceedings.mlr.press/v84/salimbeni18a.html},
	abstract = 	 {The natural gradient method has been used effectively in conjugate Gaussian process models, but the non-conjugate case has been largely unexplored. We examine how natural gradients can be used in non-conjugate stochastic settings, together with hyperparameter learning. We conclude that the natural gradient can significantly improve performance in terms of wall-clock time. For ill-conditioned posteriors the benefit of the natural gradient method is especially pronounced, and we demonstrate a practical setting where ordinary gradients are unusable. We show how natural gradients can be computed efficiently and automatically in any parameterization, using automatic differentiation. }
}


%%%% Estate of Art %%%%

@misc{Vos2023,
	abstract = {Introduction: Wearable sensors have shown promise as a non-intrusive method for collecting biomarkers that may correlate with levels of elevated stress. Stressors cause a variety of biological responses, and these physiological reactions can be measured using biomarkers including Heart Rate Variability (HRV), Electrodermal Activity (EDA) and Heart Rate (HR) that represent the stress response from the Hypothalamic-Pituitary-Adrenal (HPA) axis, the Autonomic Nervous System (ANS), and the immune system. While Cortisol response magnitude remains the gold standard indicator for stress assessment [1], recent advances in wearable technologies have resulted in the availability of a number of consumer devices capable of recording HRV, EDA and HR sensor biomarkers, amongst other signals. At the same time, researchers have been applying machine learning techniques to the recorded biomarkers in order to build models that may be able to predict elevated levels of stress. Objective: The aim of this review is to provide an overview of machine learning techniques utilized in prior research with a specific focus on model generalization when using these public datasets as training data. We also shed light on the challenges and opportunities that machine learning-enabled stress monitoring and detection face. Methods: This study reviewed published works contributing and/or using public datasets designed for detecting stress and their associated machine learning methods. The electronic databases of Google Scholar, Crossref, DOAJ and PubMed were searched for relevant articles and a total of 33 articles were identified and included in the final analysis. The reviewed works were synthesized into three categories of publicly available stress datasets, machine learning techniques applied using those, and future research directions. For the machine learning studies reviewed, we provide an analysis of their approach to results validation and model generalization. The quality assessment of the included studies was conducted in accordance with the IJMEDI checklist [2]. Results: A number of public datasets were identified that are labeled for stress detection. These datasets were most commonly produced from sensor biomarker data recorded using the Empatica E4 device, a well-studied, medical-grade wrist-worn wearable that provides sensor biomarkers most notable to correlate with elevated levels of stress. Most of the reviewed datasets contain less than twenty-four hours of data, and the varied experimental conditions and labeling methodologies potentially limit their ability to generalize for unseen data. In addition, we discuss that previous works show shortcomings in areas such as their labeling protocols, lack of statistical power, validity of stress biomarkers, and model generalization ability. Conclusion: Health tracking and monitoring using wearable devices is growing in popularity, while the generalization of existing machine learning models still requires further study, and research in this area will continue to provide improvements as newer and more substantial datasets become available.},
	author = {Gideon Vos and Kelly Trinh and Zoltan Sarnyai and Mostafa Rahimi Azghadi},
	doi = {10.1016/j.ijmedinf.2023.105026},
	issn = {18728243},
	journal = {International Journal of Medical Informatics},
	keywords = {Generalization,Machine learning,Stress,Wearable sensor},
	month = {5},
	pmid = {36893657},
	publisher = {Elsevier Ireland Ltd},
	title = {Generalizable machine learning for stress monitoring from wearable devices: A systematic literature review},
	volume = {173},
	year = {2023}
}

@article{Zhu2023,
	abstract = {Stress is an inevitable part of modern life. While stress can negatively impact a person's life and health, positive and under-controlled stress can also enable people to generate creative solutions to problems encountered in their daily lives. Although it is hard to eliminate stress, we can learn to monitor and control its physical and psychological effects. It is essential to provide feasible and immediate solutions for more mental health counselling and support programs to help people relieve stress and improve their mental health. Popular wearable devices, such as smartwatches with several sensing capabilities, including physiological signal monitoring, can alleviate the problem. This work investigates the feasibility of using wrist-based electrodermal activity (EDA) signals collected from wearable devices to predict people's stress status and identify possible factors impacting stress classification accuracy. We use data collected from wrist-worn devices to examine the binary classification discriminating stress from non-stress. For efficient classification, five machine learning-based classifiers were examined. We explore the classification performance on four available EDA databases under different feature selections. According to the results, Support Vector Machine (SVM) outperforms the other machine learning approaches with an accuracy of 92.9 for stress prediction. Additionally, when the subject classification included gender information, the performance analysis showed significant differences between males and females. We further examine a multimodal approach for stress classifications. The results indicate that wearable devices with EDA sensors have a great potential to provide helpful insight for improved mental health monitoring.},
	author = {Lili Zhu and Petros Spachos and Pai Chet Ng and Yuanhao Yu and Yang Wang and Konstantinos Plataniotis and Dimitrios Hatzinakos},
	doi = {10.1109/JBHI.2023.3239305},
	issn = {21682208},
	issue = {5},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	keywords = {EDA,Stress measurement,emotion recognition,k-nearest neighbors,logistic regression,naive bayes,random forest,smartwatches,support vector machines,wearable sensors,wrist-worn wearable device},
	month = {5},
	pages = {2155-2165},
	pmid = {37022004},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {Stress Detection Through Wrist-Based Electrodermal Activity Monitoring and Machine Learning},
	volume = {27},
	year = {2023}
}


@article{Yang2023,
	abstract = {With the rapid development of mobile and wearable devices, it is increasingly possible to access users' affective data in a more unobtrusive manner. On this basis, researchers have proposed various systems to recognize user's emotional states. However, most of these studies rely on traditional machine learning techniques and a limited number of signals, leading to systems that either do not generalize well or would frequently lack sufficient information for emotion detection in realistic scenarios. In this paper, we propose a novel attention-based LSTM system that uses a combination of sensors from a smartphone (front camera, microphone, touch panel) and a wristband (photoplethysmography, electrodermal activity, and infrared thermopile sensor) to accurately determine user's emotional states. We evaluated the proposed system by conducting a user study with 45 participants. Using collected behavioral (facial expression, speech, keystroke) and physiological (blood volume, electrodermal activity, skin temperature) affective responses induced by visual stimuli, our system was able to achieve an average accuracy of 89.2 percent for binary positive and negative emotion classification under leave-one-participant-out cross-validation. Furthermore, we investigated the effectiveness of different combinations of data signals to cover different scenarios of signal availability.},
	author = {Kangning Yang and Chaofan Wang and Yue Gu and Zhanna Sarsenbayeva and Benjamin Tag and Tilman Dingler and Greg Wadley and Jorge Goncalves},
	doi = {10.1109/TAFFC.2021.3100868},
	issn = {19493045},
	issue = {2},
	journal = {IEEE Transactions on Affective Computing},
	keywords = {Emotion recognition,attention-based LSTM,behavioral signals,mobile and wearable devices,physiological signals},
	month = {4},
	pages = {1082-1097},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	title = {Behavioral and Physiological Signals-Based Deep Multimodal Approach for Mobile Emotion Recognition},
	volume = {14},
	year = {2023}
}

% Multimodalidad
@misc{Baltrusaitis2019,
	abstract = {Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.},
	author = {Tadas Baltrusaitis and Chaitanya Ahuja and Louis Philippe Morency},
	doi = {10.1109/TPAMI.2018.2798607},
	issn = {19393539},
	issue = {2},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Multimodal,introductory,machine learning,survey},
	month = {2},
	pages = {423-443},
	pmid = {29994351},
	publisher = {IEEE Computer Society},
	title = {Multimodal Machine Learning: A Survey and Taxonomy},
	volume = {41},
	year = {2019}
}

@article{Liang2024,
	abstract = {Multimodal machine learning is a vibrant multi-disciplinary research field that aims to design computer agents with intelligent capabilities such as understanding, reasoning, and learning through integrating multiple communicative modalities, including linguistic, acoustic, visual, tactile, and physiological messages. With the recent interest in video understanding, embodied autonomous agents, text-to-image generation, and multisensor fusion in application domains such as healthcare and robotics, multimodal machine learning has brought unique computational and theoretical challenges to the machine learning community given the heterogeneity of data sources and the interconnections often found between modalities. However, the breadth of progress in multimodal research has made it difficult to identify the common themes and open questions in the field. By synthesizing a broad range of application domains and theoretical frameworks from both historical and recent perspectives, this article is designed to provide an overview of the computational and theoretical foundations of multimodal machine learning. We start by defining three key principles of modality heterogeneity, connections, and interactions that have driven subsequent innovations, and propose a taxonomy of six core technical challenges: representation, alignment, reasoning, generation, transference, and quantification covering historical and recent trends. Recent technical achievements will be presented through the lens of this taxonomy, allowing researchers to understand the similarities and differences across new approaches. We end by motivating several open problems for future research as identified by our taxonomy.},
	author = {Paul Pu Liang and Amir Zadeh and Louis Philippe Morency},
	doi = {10.1145/3656580},
	issn = {15577341},
	issue = {10},
	journal = {ACM Computing Surveys},
	keywords = {Multimodal machine learning,data heterogeneity,feature interactions,language and vision,multimedia,representation learning},
	month = {6},
	publisher = {Association for Computing Machinery},
	title = {Foundations \& Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions},
	volume = {56},
	year = {2024}
}


